{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0     40   M           ATA        140          289          0     Normal   \n",
       "1     49   F           NAP        160          180          0     Normal   \n",
       "2     37   M           ATA        130          283          0         ST   \n",
       "3     48   F           ASY        138          214          0     Normal   \n",
       "4     54   M           NAP        150          195          0     Normal   \n",
       "..   ...  ..           ...        ...          ...        ...        ...   \n",
       "913   45   M            TA        110          264          0     Normal   \n",
       "914   68   M           ASY        144          193          1     Normal   \n",
       "915   57   M           ASY        130          131          0     Normal   \n",
       "916   57   F           ATA        130          236          0        LVH   \n",
       "917   38   M           NAP        138          175          0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0      172              N      0.0       Up             0  \n",
       "1      156              N      1.0     Flat             1  \n",
       "2       98              N      0.0       Up             0  \n",
       "3      108              Y      1.5     Flat             1  \n",
       "4      122              N      0.0       Up             0  \n",
       "..     ...            ...      ...      ...           ...  \n",
       "913    132              N      1.2     Flat             1  \n",
       "914    141              N      3.4     Flat             1  \n",
       "915    115              Y      1.2     Flat             1  \n",
       "916    174              N      0.0     Flat             1  \n",
       "917    173              N      0.0       Up             0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"heart.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Sex               0\n",
       "ChestPainType     0\n",
       "RestingBP         0\n",
       "Cholesterol       0\n",
       "FastingBS         0\n",
       "RestingECG        0\n",
       "MaxHR             0\n",
       "ExerciseAngina    0\n",
       "Oldpeak           0\n",
       "ST_Slope          0\n",
       "HeartDisease      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254399</td>\n",
       "      <td>-0.095282</td>\n",
       "      <td>0.198039</td>\n",
       "      <td>-0.382045</td>\n",
       "      <td>0.258612</td>\n",
       "      <td>0.282039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RestingBP</th>\n",
       "      <td>0.254399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100893</td>\n",
       "      <td>0.070193</td>\n",
       "      <td>-0.112135</td>\n",
       "      <td>0.164803</td>\n",
       "      <td>0.107589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholesterol</th>\n",
       "      <td>-0.095282</td>\n",
       "      <td>0.100893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.260974</td>\n",
       "      <td>0.235792</td>\n",
       "      <td>0.050148</td>\n",
       "      <td>-0.232741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FastingBS</th>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.070193</td>\n",
       "      <td>-0.260974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131438</td>\n",
       "      <td>0.052698</td>\n",
       "      <td>0.267291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxHR</th>\n",
       "      <td>-0.382045</td>\n",
       "      <td>-0.112135</td>\n",
       "      <td>0.235792</td>\n",
       "      <td>-0.131438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.160691</td>\n",
       "      <td>-0.400421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oldpeak</th>\n",
       "      <td>0.258612</td>\n",
       "      <td>0.164803</td>\n",
       "      <td>0.050148</td>\n",
       "      <td>0.052698</td>\n",
       "      <td>-0.160691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeartDisease</th>\n",
       "      <td>0.282039</td>\n",
       "      <td>0.107589</td>\n",
       "      <td>-0.232741</td>\n",
       "      <td>0.267291</td>\n",
       "      <td>-0.400421</td>\n",
       "      <td>0.403951</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Age  RestingBP  Cholesterol  FastingBS     MaxHR   Oldpeak  \\\n",
       "Age           1.000000   0.254399    -0.095282   0.198039 -0.382045  0.258612   \n",
       "RestingBP     0.254399   1.000000     0.100893   0.070193 -0.112135  0.164803   \n",
       "Cholesterol  -0.095282   0.100893     1.000000  -0.260974  0.235792  0.050148   \n",
       "FastingBS     0.198039   0.070193    -0.260974   1.000000 -0.131438  0.052698   \n",
       "MaxHR        -0.382045  -0.112135     0.235792  -0.131438  1.000000 -0.160691   \n",
       "Oldpeak       0.258612   0.164803     0.050148   0.052698 -0.160691  1.000000   \n",
       "HeartDisease  0.282039   0.107589    -0.232741   0.267291 -0.400421  0.403951   \n",
       "\n",
       "              HeartDisease  \n",
       "Age               0.282039  \n",
       "RestingBP         0.107589  \n",
       "Cholesterol      -0.232741  \n",
       "FastingBS         0.267291  \n",
       "MaxHR            -0.400421  \n",
       "Oldpeak           0.403951  \n",
       "HeartDisease      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0     40    1              1        140          289          0           1   \n",
       "1     49    0              2        160          180          0           1   \n",
       "2     37    1              1        130          283          0           2   \n",
       "3     48    0              0        138          214          0           1   \n",
       "4     54    1              2        150          195          0           1   \n",
       "..   ...  ...            ...        ...          ...        ...         ...   \n",
       "913   45    1              3        110          264          0           1   \n",
       "914   68    1              0        144          193          1           1   \n",
       "915   57    1              0        130          131          0           1   \n",
       "916   57    0              1        130          236          0           0   \n",
       "917   38    1              2        138          175          0           1   \n",
       "\n",
       "     MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0      172               0      0.0         2             0  \n",
       "1      156               0      1.0         1             1  \n",
       "2       98               0      0.0         2             0  \n",
       "3      108               1      1.5         1             1  \n",
       "4      122               0      0.0         2             0  \n",
       "..     ...             ...      ...       ...           ...  \n",
       "913    132               0      1.2         1             1  \n",
       "914    141               0      3.4         1             1  \n",
       "915    115               1      1.2         1             1  \n",
       "916    174               0      0.0         1             1  \n",
       "917    173               0      0.0         2             0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sex'] = enc.fit_transform(data['Sex'])\n",
    "data['ChestPainType'] = enc.fit_transform(data['ChestPainType'])\n",
    "data['RestingECG'] = enc.fit_transform(data['RestingECG'])\n",
    "data['ExerciseAngina'] = enc.fit_transform(data['ExerciseAngina'])\n",
    "data['ST_Slope'] = enc.fit_transform(data['ST_Slope'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "randModel = RandomForestClassifier(n_estimators=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['HeartDisease','Age'],axis=1)\n",
    "y = data['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  MaxHR  \\\n",
       "0      1              1        140          289          0           1    172   \n",
       "1      0              2        160          180          0           1    156   \n",
       "2      1              1        130          283          0           2     98   \n",
       "3      0              0        138          214          0           1    108   \n",
       "4      1              2        150          195          0           1    122   \n",
       "..   ...            ...        ...          ...        ...         ...    ...   \n",
       "913    1              3        110          264          0           1    132   \n",
       "914    1              0        144          193          1           1    141   \n",
       "915    1              0        130          131          0           1    115   \n",
       "916    0              1        130          236          0           0    174   \n",
       "917    1              2        138          175          0           1    173   \n",
       "\n",
       "     ExerciseAngina  Oldpeak  ST_Slope  \n",
       "0                 0      0.0         2  \n",
       "1                 0      1.0         1  \n",
       "2                 0      0.0         2  \n",
       "3                 1      1.5         1  \n",
       "4                 0      0.0         2  \n",
       "..              ...      ...       ...  \n",
       "913               0      1.2         1  \n",
       "914               0      3.4         1  \n",
       "915               1      1.2         1  \n",
       "916               0      0.0         1  \n",
       "917               0      0.0         2  \n",
       "\n",
       "[918 rows x 10 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "913    1\n",
       "914    1\n",
       "915    1\n",
       "916    1\n",
       "917    0\n",
       "Name: HeartDisease, Length: 918, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=20)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randModel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913043478260869"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {\n",
    "    'n_estimators':[5,10,20,50],\n",
    "    'criterion':['gini','log_loss','entropy']\n",
    "}\n",
    "gcv = GridSearchCV(RandomForestClassifier(),para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [5, 10, 20, 50]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [5, 10, 20, 50]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'log_loss', 'entropy'],\n",
       "                         'n_estimators': [5, 10, 20, 50]})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'log_loss', 'n_estimators': 50}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "randModel = RandomForestClassifier(n_estimators=50,criterion='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9021739130434783"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randModel.fit(x_train,y_train)\n",
    "y_pred = randModel.predict(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89        87\n",
      "           1       0.88      0.95      0.91        97\n",
      "\n",
      "    accuracy                           0.90       184\n",
      "   macro avg       0.91      0.90      0.90       184\n",
      "weighted avg       0.90      0.90      0.90       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logiModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logiModel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_y_pred = logiModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8532608695652174"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,logi_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        87\n",
      "           1       0.85      0.88      0.86        97\n",
      "\n",
      "    accuracy                           0.85       184\n",
      "   macro avg       0.85      0.85      0.85       184\n",
      "weighted avg       0.85      0.85      0.85       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,logi_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test,logi_y_pred),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraLogi = {\n",
    "    'penalty':['none','l1','l2','elasticnet'],\n",
    "    'C':[1,0.1,10,0.001],\n",
    "    'solver':['newton-cg','lbfgs','liblinear','sag','saga']\n",
    "}\n",
    "\n",
    "gcvLogi = GridSearchCV(LogisticRegression(),paraLogi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.84869071 0.83779704        nan 0.73436772 0.70711956        nan\n",
      "        nan 0.84053676        nan 0.70711956 0.85005125 0.84189731\n",
      " 0.84325785 0.73164663 0.70711956        nan        nan        nan\n",
      "        nan        nan 0.84869071 0.83779704        nan 0.73164663\n",
      " 0.70711956        nan        nan 0.84191594        nan 0.70575902\n",
      " 0.84463703 0.8460069  0.8460069  0.73164663 0.70711956        nan\n",
      "        nan        nan        nan        nan 0.84869071 0.83779704\n",
      "        nan 0.73436772 0.70711956        nan        nan 0.84733016\n",
      "        nan 0.70711956 0.84869071 0.8446184  0.84596962 0.73436772\n",
      " 0.70711956        nan        nan        nan        nan        nan\n",
      " 0.84869071 0.83779704        nan 0.73300718 0.70711956        nan\n",
      "        nan 0.65120678        nan 0.65257665 0.72752772 0.72752772\n",
      " 0.72347405 0.71120119 0.70575902        nan        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 0.1, 10, 0.001],\n",
       "                         &#x27;penalty&#x27;: [&#x27;none&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 0.1, 10, 0.001],\n",
       "                         &#x27;penalty&#x27;: [&#x27;none&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 0.1, 10, 0.001],\n",
       "                         'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcvLogi.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcvLogi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "logiModel = LogisticRegression(penalty='l2',C=1,solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, solver='newton-cg')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logiModel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_y_pred = logiModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8532608695652174"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,logi_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test,logi_y_pred),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        87\n",
      "           1       0.85      0.88      0.86        97\n",
      "\n",
      "    accuracy                           0.85       184\n",
      "   macro avg       0.85      0.85      0.85       184\n",
      "weighted avg       0.85      0.85      0.85       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,logi_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
